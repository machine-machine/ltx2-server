version: '3.8'

services:
  ltx2:
    build: .
    container_name: ltx2-server
    volumes:
      - ltx2-models:/models
      - ltx2-outputs:/outputs
    networks:
      - coolify
      - default
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['1']
              capabilities: [gpu]
    shm_size: '8g'
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "true"]
      interval: 30s
      timeout: 5s
      start_period: 5s
      retries: 1

networks:
  coolify:
    external: true

volumes:
  ltx2-models:
  ltx2-outputs:
